{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run spark.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = spark.read.csv('./feature.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1150164"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime id: 2018-05-22, train count: 780063, test count: 35733\n",
      "1 grids of 129 processed\n",
      "2 grids of 129 processed\n",
      "3 grids of 129 processed\n",
      "4 grids of 129 processed\n",
      "5 grids of 129 processed\n",
      "6 grids of 129 processed\n",
      "7 grids of 129 processed\n",
      "8 grids of 129 processed\n",
      "9 grids of 129 processed\n",
      "10 grids of 129 processed\n",
      "11 grids of 129 processed\n",
      "12 grids of 129 processed\n",
      "13 grids of 129 processed\n",
      "14 grids of 129 processed\n",
      "15 grids of 129 processed\n",
      "16 grids of 129 processed\n",
      "17 grids of 129 processed\n",
      "18 grids of 129 processed\n",
      "19 grids of 129 processed\n",
      "20 grids of 129 processed\n",
      "21 grids of 129 processed\n",
      "22 grids of 129 processed\n",
      "23 grids of 129 processed\n",
      "24 grids of 129 processed\n",
      "25 grids of 129 processed\n",
      "26 grids of 129 processed\n",
      "27 grids of 129 processed\n",
      "28 grids of 129 processed\n",
      "29 grids of 129 processed\n",
      "30 grids of 129 processed\n",
      "31 grids of 129 processed\n",
      "32 grids of 129 processed\n",
      "33 grids of 129 processed\n",
      "34 grids of 129 processed\n",
      "35 grids of 129 processed\n",
      "36 grids of 129 processed\n",
      "37 grids of 129 processed\n",
      "38 grids of 129 processed\n",
      "39 grids of 129 processed\n",
      "40 grids of 129 processed\n",
      "41 grids of 129 processed\n",
      "42 grids of 129 processed\n",
      "43 grids of 129 processed\n",
      "44 grids of 129 processed\n",
      "45 grids of 129 processed\n",
      "46 grids of 129 processed\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "\n",
    "feature_cols = [\"surge\", \"hour\", \"weekday\", \"speedLaged\", \"hamsCountLaged\", \"m1\", \"m2\", \"m3\",\n",
    "            \"d0\", \"d1\", \"d2\", \"w0\", \"w1\", \"w2\", \"sd\", \"cd\", \"sw\", \"cw\"]\n",
    "meta_cols = ['gridId', 'datetimeId', 'hourGroup', 'count', 'm1', 'm2', 'm3']\n",
    "label_col = 'count'\n",
    "\n",
    "transformed = (\n",
    "    feature_df\n",
    "    .select(feature_cols + [label_col] + meta_cols)\n",
    "    .rdd\n",
    "    .map(lambda r: (Vectors.dense(r[:len(feature_cols)]), r[label_col]) + r[-len(meta_cols):])\n",
    "    .toDF(['features', 'label'] + meta_cols)\n",
    ")\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from datetime import datetime, date, timedelta\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "# TODO increase maxCategories, so weekday can be interpreted as category\n",
    "\n",
    "data = transformed\n",
    "test_datetime_id = date(2018, 5, 22)\n",
    "last_datetime_id = date(2018, 6, 1)\n",
    "\n",
    "data.persist()\n",
    "\n",
    "feature_indexer = VectorIndexer(inputCol=\"features\", \\\n",
    "                               outputCol=\"indexedFeatures\",\\\n",
    "                               maxCategories=10).fit(data)\n",
    "\n",
    "prediction_path = './per_grid_random_forest.csv'\n",
    "if os.path.exists(prediction_path) and os.path.isdir(prediction_path):\n",
    "    shutil.rmtree(prediction_path)\n",
    "\n",
    "# print(data.agg({'datetimeId': 'min'}).collect()[0])\n",
    "    \n",
    "while test_datetime_id < last_datetime_id:\n",
    "    start_datetime_id = test_datetime_id - timedelta(days=21)\n",
    "    train = data.filter(F.col('datetimeId') >= start_datetime_id).filter(F.col('datetimeId') < test_datetime_id)\n",
    "    test = data.filter(F.to_date('datetimeId') == test_datetime_id)\n",
    "        \n",
    "    print('datetime id: {}, train count: {}, test count: {}'.format(test_datetime_id, train.count(), test.count()))\n",
    "\n",
    "    from pyspark.ml.regression import RandomForestRegressor\n",
    "  \n",
    "    predictions = []\n",
    "    grid_ids = test.select(F.col(\"gridId\")).distinct().collect()\n",
    "    for c, grid_id_row in enumerate(grid_ids):\n",
    "        grid_id = grid_id_row.gridId\n",
    "        train_part = train.filter(F.col(\"gridId\") == grid_id)\n",
    "        test_part = test.filter(F.col(\"gridId\") == grid_id)\n",
    "        rf = RandomForestRegressor(numTrees=50, minInstancesPerNode=1, featuresCol='indexedFeatures')\n",
    "        pipeline = Pipeline(stages=[feature_indexer, rf])\n",
    "        model = pipeline.fit(train)\n",
    "        \n",
    "        p = model.transform(test)\n",
    "        predictions.append(p)\n",
    "                                \n",
    "        print(\"{} grids of {} processed\".format(c+1, len(grid_ids)))\n",
    "    \n",
    "    prediction = predictions[0]\n",
    "    for p in predictions[1:]:\n",
    "       prediction = prediction.union(p)\n",
    "        \n",
    "    prediction = prediction.select('gridId', 'datetimeId', 'prediction', 'label')\n",
    "    \n",
    "    prediction.write.csv(prediction_path, mode='append', header=False)\n",
    "\n",
    "    prediction = prediction.groupBy('gridId').agg((F.sum(F.abs(prediction['prediction']-prediction['label'])\\\n",
    "            /prediction['label']*F.sqrt(prediction['label'])) / F.sum(F.sqrt(prediction['label']))).alias('err'))\n",
    "    \n",
    "    print(\"avg error: {}\".format(prediction.agg({'err': 'avg'}).collect()[0]))\n",
    "#     evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    \n",
    "#     rmse = evaluator.evaluate(prediction)\n",
    "    \n",
    "#     print(\"datetime id: {}, rmse: {}\".format(test_datetime_id, rmse))\n",
    "    \n",
    "    test_datetime_id += timedelta(days=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
